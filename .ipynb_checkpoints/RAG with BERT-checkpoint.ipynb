{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7771c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9545195-932e-4192-9c56-c44aab6c72c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc3d2267-5a8e-4ea4-9388-6af1a6dab16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.68263053894043 Around 9 Million people live in London\n",
      "16.25380516052246 London is known for its financial district\n"
     ]
    }
   ],
   "source": [
    "# from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# query = \"How many people live in London?\"\n",
    "# docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "\n",
    "# #Load the model\n",
    "# model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "# #Encode query and documents\n",
    "# query_emb = model.encode(query)\n",
    "# doc_emb = model.encode(docs)\n",
    "\n",
    "# #Compute dot score between query and all document embeddings\n",
    "# scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "# #Combine docs & scores\n",
    "# doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "# #Sort by decreasing score\n",
    "# doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# #Output passages & scores\n",
    "# for doc, score in doc_score_pairs:\n",
    "#     print(score, doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a8db4-6473-4518-b6bb-8b5d4228df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer, util\n",
    "# import os\n",
    "\n",
    "# query = \"Where was the witness born?\"\n",
    "# docs_dir = 'data'\n",
    "# docs = []\n",
    "\n",
    "# # Read text from .txt files in the 'data' folder while handling decoding errors\n",
    "# for filename in os.listdir(docs_dir):\n",
    "#     if filename.endswith(\".txt\"):\n",
    "#         file_path = os.path.join(docs_dir, filename)\n",
    "#         with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "#             text = file.read()\n",
    "#             docs.append(text)\n",
    "\n",
    "# # Load the model\n",
    "# model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "# # Encode query and documents\n",
    "# query_emb = model.encode(query)\n",
    "# doc_emb = model.encode(docs)\n",
    "\n",
    "# # Compute dot score between query and all document embeddings\n",
    "# scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "# # Combine docs & scores\n",
    "# doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "# # Sort by decreasing score\n",
    "# doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Output passages & scores\n",
    "# for doc, score in doc_score_pairs:\n",
    "#     print(\"scre\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c63fcdb-0d2f-4834-a43d-967d84dac5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where was the witness born?\n",
      "Answer: Plaszow\n",
      "\n",
      "Question: When was the witness born?\n",
      "Answer: 1924\n",
      "\n",
      "Question: How many sisters and brothers the witness has?\n",
      "Answer: seven brothers\n",
      "\n",
      "Question: How many Jews were in the ghetto?\n",
      "Answer: over 30,000\n",
      "\n",
      "Question: who had a shop for stationery and writing materials?\n",
      "Answer: Moshe Zucker\n",
      "\n",
      "Question: Who was the youngest daughter in the witness's house?\n",
      "Answer: .\n",
      "\n",
      "Question: who is the Interviewer?\n",
      "Answer: Yitzhak Alfrovitz\n",
      "\n",
      "Question: When was the random ghetto established?\n",
      "Answer: .\n",
      "\n",
      "Question: What scared the witness the most?\n",
      "Answer: the period when the Aktionen began\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# Define the path to the directory containing text documents\n",
    "docs_dir = 'data'\n",
    "\n",
    "questions = [\n",
    "    \"Where was the witness born?\",\n",
    "    \"When was the witness born?\",\n",
    "    \"How many sisters and brothers the witness has?\",\n",
    "    \"How many Jews were in the ghetto?\",\n",
    "    \"who had a shop for stationery and writing materials?\",\n",
    "    \"Who was the youngest daughter in the witness's house?\",\n",
    "    \"who is the Interviewer?\",\n",
    "    \"When was the random ghetto established?\",\n",
    "    \"What scared the witness the most?\"\n",
    "\n",
    "]\n",
    "\n",
    "# Select a supported model for question-answering\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"  \n",
    "\n",
    "# For example, using BERT model\n",
    "nlp = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "# Iterate over each text file, extract answers to questions individually\n",
    "for filename in os.listdir(docs_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(docs_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            text = file.read()\n",
    "            \n",
    "            # Iterate over the questions and extract answers from the current text document\n",
    "            for question in questions:\n",
    "                result = nlp(question=question, context=text)\n",
    "                print(f\"Question: {question}\")\n",
    "                print(f\"Answer: {result['answer']}\")\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b0d976-a90f-46df-a69b-a62f11b3a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad6e81a8fb94902bfb81a3cde134b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\The user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\The user\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-cased-distilled-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de425fe317647709a61c4656d7735ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17c4e5ffb6447cc9c1745df3908aa1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184007d533004f14ace5c83272caa982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea907150b504118a63773e271ffda7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8953391313552856, 'start': 250, 'end': 255, 'answer': 'Radom'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "docs_dir = 'data'\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "question = \"Where was the witness born?\"\n",
    "for filename in os.listdir(docs_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(docs_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            context = file.read()\n",
    "qa_model(question = question, context = context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cb93b88-02c2-4251-89e3-a833ee7840eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8043004870414734,\n",
       " 'start': 52174,\n",
       " 'end': 52197,\n",
       " 'answer': 'until the 24th of April'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "docs_dir = 'data'\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "question = \"How many sisters and brothers the witness has?\"\n",
    "for filename in os.listdir(docs_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(docs_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            context = file.read()\n",
    "qa_model(question = question, context = context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a12e17bd-58b1-4ccb-b2c1-75b9171707b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8133560419082642,\n",
       " 'start': 586,\n",
       " 'end': 598,\n",
       " 'answer': 'Moshe Zucker'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "docs_dir = 'data'\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "question = \"who had a shop for stationery and writing materials?\" \n",
    " \n",
    "for filename in os.listdir(docs_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(docs_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            context = file.read()\n",
    "qa_model(question = question, context = context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4c5def2-1f10-45f8-96b5-83d7fd1fbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9267848134040833,\n",
       " 'start': 63912,\n",
       " 'end': 63933,\n",
       " 'answer': 'Mrs. Yaffa Goldwasser'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "docs_dir = 'data'\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "question = \"Who was the youngest daughter in the witness's house?\" \n",
    " \n",
    "for filename in os.listdir(docs_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(docs_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            context = file.read()\n",
    "qa_model(question = question, context = context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21b03e0e-1413-4eda-8cac-b550dcb6836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8566189408302307,\n",
       " 'start': 52174,\n",
       " 'end': 52197,\n",
       " 'answer': 'until the 24th of April'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "docs_dir = 'data'\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "question = \"How many Jews were in the ghetto?\" \n",
    " \n",
    "for filename in os.listdir(docs_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(docs_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            context = file.read()\n",
    "qa_model(question = question, context = context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "361b732a-fb1b-42bd-8c38-6ceb90ecee7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9922620058059692,\n",
       " 'start': 85,\n",
       " 'end': 102,\n",
       " 'answer': 'Yitzhak Alfrovitz'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "docs_dir = 'data'\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "question = \"who is the Interviewer?\"\n",
    " \n",
    "for filename in os.listdir(docs_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(docs_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            context = file.read()\n",
    "qa_model(question = question, context = context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e092953-032a-4d30-a3c2-f212a38e0bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8433804512023926,\n",
       " 'start': 6521,\n",
       " 'end': 6534,\n",
       " 'answer': 'November 1942'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "docs_dir = 'data'\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "question = \"When was the random ghetto established?\"\n",
    " \n",
    "for filename in os.listdir(docs_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(docs_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            context = file.read()\n",
    "qa_model(question = question, context = context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "522240cf-4ff9-4f86-b49e-81dd899baf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9168049693107605,\n",
       " 'start': 63912,\n",
       " 'end': 63933,\n",
       " 'answer': 'Mrs. Yaffa Goldwasser'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "docs_dir = 'data'\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "question = \"What scared the witness the most?\"\n",
    " \n",
    "for filename in os.listdir(docs_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(docs_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            context = file.read()\n",
    "qa_model(question = question, context = context)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
