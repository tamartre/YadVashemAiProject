{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7771c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9545195-932e-4192-9c56-c44aab6c72c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc3d2267-5a8e-4ea4-9388-6af1a6dab16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.68263053894043 Around 9 Million people live in London\n",
      "16.25380516052246 London is known for its financial district\n"
     ]
    }
   ],
   "source": [
    "# from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# query = \"How many people live in London?\"\n",
    "# docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "\n",
    "# #Load the model\n",
    "# model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "# #Encode query and documents\n",
    "# query_emb = model.encode(query)\n",
    "# doc_emb = model.encode(docs)\n",
    "\n",
    "# #Compute dot score between query and all document embeddings\n",
    "# scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "# #Combine docs & scores\n",
    "# doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "# #Sort by decreasing score\n",
    "# doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# #Output passages & scores\n",
    "# for doc, score in doc_score_pairs:\n",
    "#     print(score, doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a8db4-6473-4518-b6bb-8b5d4228df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer, util\n",
    "# import os\n",
    "\n",
    "# query = \"Where was the witness born?\"\n",
    "# docs_dir = 'data'\n",
    "# docs = []\n",
    "\n",
    "# # Read text from .txt files in the 'data' folder while handling decoding errors\n",
    "# for filename in os.listdir(docs_dir):\n",
    "#     if filename.endswith(\".txt\"):\n",
    "#         file_path = os.path.join(docs_dir, filename)\n",
    "#         with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "#             text = file.read()\n",
    "#             docs.append(text)\n",
    "\n",
    "# # Load the model\n",
    "# model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "# # Encode query and documents\n",
    "# query_emb = model.encode(query)\n",
    "# doc_emb = model.encode(docs)\n",
    "\n",
    "# # Compute dot score between query and all document embeddings\n",
    "# scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "# # Combine docs & scores\n",
    "# doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "# # Sort by decreasing score\n",
    "# doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Output passages & scores\n",
    "# for doc, score in doc_score_pairs:\n",
    "#     print(\"scre\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c63fcdb-0d2f-4834-a43d-967d84dac5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where was the witness born?\n",
      "Answer: Plaszow\n",
      "\n",
      "Question: When was the witness born?\n",
      "Answer: 1924\n",
      "\n",
      "Question: How many sisters and brothers the witness has?\n",
      "Answer: seven brothers\n",
      "\n",
      "Question: How many Jews were in the ghetto?\n",
      "Answer: over 30,000\n",
      "\n",
      "Question: who had a shop for stationery and writing materials?\n",
      "Answer: Moshe Zucker\n",
      "\n",
      "Question: Who was the youngest daughter in the witness's house?\n",
      "Answer: .\n",
      "\n",
      "Question: who is the Interviewer?\n",
      "Answer: Yitzhak Alfrovitz\n",
      "\n",
      "Question: When was the random ghetto established?\n",
      "Answer: .\n",
      "\n",
      "Question: What scared the witness the most?\n",
      "Answer: the period when the Aktionen began\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# Define the path to the directory containing text documents\n",
    "docs_dir = 'data'\n",
    "\n",
    "questions = [\n",
    "    \"Where was the witness born?\",\n",
    "    \"When was the witness born?\",\n",
    "    \"How many sisters and brothers the witness has?\",\n",
    "    \"How many Jews were in the ghetto?\",\n",
    "    \"who had a shop for stationery and writing materials?\",\n",
    "    \"Who was the youngest daughter in the witness's house?\",\n",
    "    \"who is the Interviewer?\",\n",
    "    \"When was the random ghetto established?\",\n",
    "    \"What scared the witness the most?\"\n",
    "\n",
    "]\n",
    "\n",
    "# Select a supported model for question-answering\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"  \n",
    "\n",
    "# For example, using BERT model\n",
    "nlp = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "# Iterate over each text file, extract answers to questions individually\n",
    "for filename in os.listdir(docs_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(docs_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            text = file.read()\n",
    "            \n",
    "            # Iterate over the questions and extract answers from the current text document\n",
    "            for question in questions:\n",
    "                result = nlp(question=question, context=text)\n",
    "                print(f\"Question: {question}\")\n",
    "                print(f\"Answer: {result['answer']}\")\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b0d976-a90f-46df-a69b-a62f11b3a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where was the witness born?\n",
      "Answer: Radom\n",
      "\n",
      "Question: When was the witness born?\n",
      "Answer: a few months\n",
      "\n",
      "Question: How many sisters and brothers the witness has?\n",
      "Answer: until the 24th of April\n",
      "\n",
      "Question: How many Jews were in the ghetto?\n",
      "Answer: until the 24th of April\n",
      "\n",
      "Question: who had a shop for stationery and writing materials?\n",
      "Answer: Moshe Zucker\n",
      "\n",
      "Question: Who was the youngest daughter in the witness's house?\n",
      "Answer: Mrs. Yaffa Goldwasser\n",
      "\n",
      "Question: who is the Interviewer?\n",
      "Answer: Yitzhak Alfrovitz\n",
      "\n",
      "Question: When was the random ghetto established?\n",
      "Answer: November 1942\n",
      "\n",
      "Question: What scared the witness the most?\n",
      "Answer: Mrs. Yaffa Goldwasser\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "docs_dir = 'data'\n",
    "\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "\n",
    "questions = [\n",
    "\"Where was the witness born?\",\n",
    "\"When was the witness born?\",\n",
    "\"How many sisters and brothers the witness has?\",\n",
    "\"How many Jews were in the ghetto?\",\n",
    "\"who had a shop for stationery and writing materials?\",\n",
    "\"Who was the youngest daughter in the witness's house?\",\n",
    "\"who is the Interviewer?\",\n",
    "\"When was the random ghetto established?\",\n",
    "\"What scared the witness the most?\"\n",
    "]\n",
    "\n",
    "for filename in os.listdir(docs_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(docs_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            context = file.read()\n",
    "nlp = pipeline(\n",
    "    \"question-answering\"\n",
    ")\n",
    "\n",
    "for question in questions:\n",
    "    result = nlp(question=question, context=context) \n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283a60d-9c84-43b2-a8d5-3426600f38e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
